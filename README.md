Great! Hereâ€™s the updated README.md tailored for your repo website-scraper:

â¸»


# ğŸ•¸ï¸ Website Scraper

**website-scraper** is a multi-threaded Python crawler that recursively scans a single domain, extracting visible text, page metadata, images, and downloadable files. Results are saved in a clean JSON format.

---

## ğŸš€ Features

- ğŸ”„ Multi-threaded crawling using `ThreadPoolExecutor`
- ğŸŒ Stays within the target domain
- ğŸ§  Extracts:
  - Page title & meta description
  - Visible text content (`h1â€“h6`, `p`, `li`)
  - Image URLs (`<img src=...>`)
  - File links (e.g., `.pdf`, `.zip`, `.docx`)
- âœ… Deduplicates visited URLs
- ğŸ“ Outputs to a single `.json` file per domain

---

## ğŸ› ï¸ Setup

### 1. Install Python (3.9+)

```bash
python3 --version

2. Clone the repository

git clone https://github.com/your-username/website-scraper.git
cd website-scraper

3. (Optional but recommended) Create a virtual environment

python3 -m venv .venv
source .venv/bin/activate     # macOS/Linux
# OR
.venv\Scripts\activate.bat    # Windows

4. Install dependencies

pip install -r requirements.txt

If you donâ€™t have requirements.txt, install manually:

pip install requests beautifulsoup4 tqdm


â¸»

â–¶ï¸ Usage

Crawl a website:

python scrape_site.py https://example.com

This will crawl all internal pages on example.com and save the output to:

example_com_content.json

Example:

python scrape_site.py https://pilvio.com


â¸»

ğŸ§¾ Output Format

[
  {
    "url": "https://example.com/page",
    "title": "Welcome to Example",
    "description": "Example description",
    "text": "Visible text content from the page...",
    "images": [
      "https://example.com/assets/logo.png"
    ],
    "files": [
      "https://example.com/files/brochure.pdf"
    ]
  },
  ...
]


â¸»

ğŸ”§ Configuration

Edit the following values in scrape_site.py if needed:
	â€¢	MAX_WORKERS = 10 â†’ Number of threads
	â€¢	MAX_PAGES = None â†’ Limit the number of pages (e.g. 200)
	â€¢	TIMEOUT = 15 â†’ HTTP timeout in seconds

â¸»

ğŸ§¹ Cleanup

To deactivate your virtual environment:

deactivate

To remove it:

rm -rf .venv


â¸»

ğŸ“„ License

MIT License Â© 2025 Kaur Kiisler

â¸»

ğŸ§  Notes
	â€¢	This tool does not obey robots.txt
	â€¢	Use responsibly on public websites
	â€¢	Consider adding robots.txt respect if you plan to share or deploy publicly

